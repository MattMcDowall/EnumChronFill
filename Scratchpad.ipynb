{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "186fdbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os.path import exists as file_exists\n",
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "import re\n",
    "import requests\n",
    "from time import sleep\n",
    "import xmltodict\n",
    "import Credentials      # Get API keys, etc.\n",
    "\n",
    "apikey = Credentials.prod_api\n",
    "baseurl = 'https://api-na.hosted.exlibrisgroup.com'\n",
    "item_query = '/almaws/v1/bibs/{mms_id}/holdings/{holding_id}/items/{item_pid}?apikey={apikey}'\n",
    "\n",
    "exported_csv = \"FullItemList.csv\"\n",
    "filled_csv = \"FilledEnumChron.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b0706ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get MMS/Holding/Item IDs, Descriptions, Locations from spreadsheet ###\n",
    "# Depending on how the file was exported, column names may or may have either spaces or underscores\n",
    "df = pd.read_csv(exported_csv, converters={'Item_ID': str, 'Holdings_ID': str, 'MMS_ID': str, 'Item ID': str, 'Holdings ID': str, 'MMS ID': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7adaf483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces from column names\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "# Rename certain columns\n",
    "df = df.rename(columns={'Permanent_Location': 'Location', 'Item_Policy': 'Policy', 'Material_Type': 'Material'})\n",
    "# # Pare it down to just the necessary columns\n",
    "# df = df[['MMS_ID', 'Holdings_ID', 'Item_ID', 'Description', 'Location']]\n",
    "# Strip leading/trailing space from Description\n",
    "df.Description = df.Description.str.strip()\n",
    "# Collapse multiple spaces within the Description\n",
    "df.Description.replace(' +', ' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c337513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for the Enum/Chron fields\n",
    "EC_fields = ['Enum_A', 'Enum_B', 'Chron_I', 'Chron_J']\n",
    "df[EC_fields] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c904f9c2",
   "metadata": {},
   "source": [
    "##### Just so we have a sample record with a Chron field filled\n",
    "df.loc[0, 'Chron_I'] = 'Whatever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "983e780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_extract(regex, these_fields):\n",
    "    exp = re.compile(regex)\n",
    "    for i, f in enumerate(these_fields):\n",
    "        df[f] = df['Description'].str.extract(exp, expand=True)[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0daf1",
   "metadata": {},
   "source": [
    "#### So that's the function. Now just call it repeatedly for each regex that you come up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8576ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match descriptions with just volume & nothing else\n",
    "fill_and_extract(r'^v\\.(\\d)+$', ['Enum_A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af8e22",
   "metadata": {},
   "source": [
    "#### Then once all those replacements are done, pull filled-in records out to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "184ebb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to hold JUST records that get filled\n",
    "filled = pd.DataFrame()\n",
    "# Populate the new dataframe with any records that now have at least one Enum/Chron field filled\n",
    "filled = df.dropna(subset=EC_fields, thresh=1)\n",
    "\n",
    "# Purge records from the original dataframe if they are now in the new one\n",
    "df = df.loc[~df['Item_ID'].isin(filled['Item_ID'])]\n",
    "\n",
    "# Add a timestamp column to the `filled` dataframe\n",
    "filled.insert(0, \"Timestamp\", datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616e77e",
   "metadata": {},
   "source": [
    "#### Do the spreadsheet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5caf9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the 'filled' dataframe to a CSV\n",
    "needs_header=not file_exists(filled_csv)    # Creating the file, so.\n",
    "filled.to_csv(filled_csv, mode='a', index=False, header=needs_header)\n",
    "# Replace Full CSV with what remains\n",
    "df.to_csv(exported_csv, mode='w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b117c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = len(filled)\n",
    "c = 0\n",
    "for index, row in filled.fillna('').iterrows():\n",
    "    c += 1\n",
    "    if (c % (records/100) < 1):\n",
    "        print(int(100*c/records), '% complete', sep='', end='\\r')\n",
    "        sleep(5)\n",
    "    print(c, str(row['Item_ID']), str(row['Holdings_ID']), str(row['MMS_ID']), sep=\"\\t\")\n",
    "    r = requests.get(''.join([baseurl,item_query.format(mms_id=str(row['MMS_ID']), holding_id=str(row['Holdings_ID']), item_pid=str(row['Item_ID']), apikey=apikey)]))\n",
    "    rdict = xmltodict.parse(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1ebf5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdict['item']['item_data']['enumeration_a'] = str(row['Enum_A'])\n",
    "rdict['item']['item_data']['enumeration_b'] = str(row['Enum_B'])\n",
    "rdict['item']['item_data']['chronology_i'] = str(row['Chron_I'])\n",
    "rdict['item']['item_data']['chronology_j'] = str(row['Chron_J'])\n",
    "# Set an internal note, if there's one available\n",
    "if (rdict['item']['item_data']['internal_note_1'] is None):\n",
    "    rdict['item']['item_data']['internal_note_1'] = 'Enum/Chron derived from Description'\n",
    "elif (rdict['item']['item_data']['internal_note_2'] is None):\n",
    "    rdict['item']['item_data']['internal_note_2'] = 'Enum/Chron derived from Description'\n",
    "elif (rdict['item']['item_data']['internal_note_3'] is None):\n",
    "    rdict['item']['item_data']['internal_note_3'] = 'Enum/Chron derived from Description'\n",
    "else:\n",
    "    print()\n",
    "    print(\"No internal note available for item MMS ID\", str(row['MMS_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8cf8220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rxml = xmltodict.unparse(rdict)\n",
    "r = requests.put(''.join([baseurl, item_query.format(mms_id=row['MMS_ID'], holding_id=row['Holdings_ID'], item_pid=row['Item_ID'], apikey=apikey)]), data=rxml.encode('utf-8'), headers={'Content-Type': 'application/xml'})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
