{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186fdbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os.path import exists as file_exists\n",
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "import re\n",
    "import requests\n",
    "from time import sleep\n",
    "import xmltodict\n",
    "import Credentials      # Get API keys, etc.\n",
    "\n",
    "apikey = Credentials.prod_api\n",
    "baseurl = 'https://api-na.hosted.exlibrisgroup.com'\n",
    "item_query = '/almaws/v1/bibs/{mms_id}/holdings/{holding_id}/items/{item_pid}?apikey={apikey}'\n",
    "\n",
    "exported_csv = \"FullItemList.csv\"\n",
    "filled_csv = \"FilledEnumChron.csv\"\n",
    "err_log_txt = \"log.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52ac8a",
   "metadata": {},
   "source": [
    "### Run this cell if you want to use the Limited-list CSV\n",
    "exported_csv = \"LimitedList.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60e89d",
   "metadata": {},
   "source": [
    "#### Create original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b0706ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on how the file was exported, column names may or may have either spaces or underscores\n",
    "df = pd.read_csv(exported_csv, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918ffd4",
   "metadata": {},
   "source": [
    "#### Clean up, tweak & format df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7adaf483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces from column names\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "# Rename certain columns\n",
    "df = df.rename(columns={'Permanent_Location': 'Location', 'Item_Policy': 'Policy', 'Material_Type': 'Material'})\n",
    "# Strip leading/trailing space from Description\n",
    "df.Description = df.Description.str.strip()\n",
    "# Collapse multiple spaces within the Description\n",
    "df.Description.replace(' +', ' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c337513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for the Enum/Chron fields\n",
    "EC_fields = ['Enum_A', 'Enum_B', 'Chron_I', 'Chron_J']\n",
    "df[EC_fields] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bfde9",
   "metadata": {},
   "source": [
    "#### The function for getting info from Description to Enum/Chron fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "983e780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_extract(regex, these_fields):\n",
    "    exp = re.compile(regex, re.IGNORECASE)\n",
    "    for i, f in enumerate(these_fields):\n",
    "        df[f] = df['Description'].str.extract(exp, expand=True)[i].fillna(df[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c90144",
   "metadata": {},
   "source": [
    "#### Set some common expressions that can be used in a modular way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1d911606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Month/season\n",
    "mmmRE = r'(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|June?|July?|Aug(?:ust)?|Sept?(?:ember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?|Spr(?:ing)?|Sum(?:mer)?|Fall?|Aut(?:umn)?|Win(?:ter)?)'\n",
    "# Month + date(s)\n",
    "mmm_ddRE = mmmRE + r'(?: \\d{1,2}(?:[\\-\\/]\\d{1,2})?)?'\n",
    "# 4-digit year/range of years (post-18th-century)\n",
    "yyyyRE = r'(?:1[89]|20)\\d{2}'\n",
    "# 4-digit year leading to a range\n",
    "yyyy_yyRE = r'(?:1[89]|20)\\d{2}-(?:\\d{2}|\\d{4})'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0daf1",
   "metadata": {},
   "source": [
    "#### Call it repeatedly for each regex that you come up with:\n",
    "**[Test your Regex here](https://regex101.com/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "25e17b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just volume(s) & nothing else\n",
    "fill_and_extract(r'^v\\. ?(\\d+[a-z]?(?:[\\&\\-]\\d+)?)$',\n",
    "                 ['Enum_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ced5fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume + issue\n",
    "fill_and_extract(r'^v\\. ?(\\d+)[ \\/]no\\. ?(\\d+)$',\n",
    "                 ['Enum_A', 'Enum_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "db272298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vol + issue + date + year\n",
    "fill_and_extract(r'^v\\. ?(\\d+)[ \\/]no\\. ?(\\d+) (' + mmm_ddRE + r'),? (' + yyyyRE + ')$',\n",
    "                 ['Enum_A', 'Enum_B', 'Chron_J', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f88af21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume + year(s)\n",
    "fill_and_extract(r'^v\\. ?(\\d+) +(\\(?' + yyyy_yyRE + r'\\)?)$',\n",
    "                 ['Enum_A', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aee6e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just issue & nothing else\n",
    "fill_and_extract(r'^no\\. ?(\\d+)$',\n",
    "                 ['Enum_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7ef8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue + year(s)\n",
    "fill_and_extract(r'^no\\. ?(\\d+) (' + yyyy_yyRE + r')$',\n",
    "                 ['Enum_B', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0b1a765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of dates within one calendar year\n",
    "fill_and_extract(r'^(' + mmm_ddRE + r'[\\-\\/]' + mmm_ddRE + '), (' + yyyyRE + ')$',\n",
    "                 ['Chron_J', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f1b7319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date + year\n",
    "fill_and_extract(r'^(' + mmm_ddRE + '),? (' + yyyyRE + ')$',\n",
    "                 ['Chron_J', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb06545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just year/range of years\n",
    "fill_and_extract(r'^(' + yyyy_yyRE + r')$',\n",
    "                 ['Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dff7e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year(s) + volume(s)\n",
    "fill_and_extract(r'^(' + yyyy_yyRE + r') v\\. ?(\\d+(?:[\\-\\/]\\d+)?)$',\n",
    "                 ['Chron_I', 'Enum_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "650400e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year + month/season/date\n",
    "fill_and_extract(r'^(' + yyyyRE + r') (' + mmm_ddRE + r')$',\n",
    "                 ['Chron_I', 'Chron_J'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af8e22",
   "metadata": {},
   "source": [
    "#### Then once all those replacements are done, pull filled-in records out to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "184ebb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to hold JUST records that get filled\n",
    "filled = pd.DataFrame()\n",
    "# Populate the new dataframe with any records that now have at least one Enum/Chron field filled\n",
    "filled = df.dropna(subset=EC_fields, thresh=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a955610",
   "metadata": {},
   "source": [
    "#### Then apply the changes via the API and log filled items to the Filled CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ca0ea802",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = len(filled)\n",
    "c = 0\n",
    "needs_header=not file_exists(filled_csv) # Apparently we're creating the file, so it needs a header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0f6beb38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Run this bit to see what got \"filled\" before hitting the API\n",
    "\n",
    "for index, row in filled.fillna('').iterrows():\n",
    "    c += 1\n",
    "    print(c, ' / '.join([row['MMS_ID'], row['Holdings_ID'], row['Item_ID']]),\n",
    "          str(row['Description']),\n",
    "          ' | '.join(x or '' for x in [row['Enum_A'], row['Enum_B'], row['Chron_I'], row['Chron_J']]),\n",
    "          sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26d3661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86660ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697cccac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb28261f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5092f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(err_log_txt, 'a') as err_log:\n",
    "    for index, row in filled.fillna('').iterrows():\n",
    "        c += 1\n",
    "        r = requests.get(''.join([baseurl,\n",
    "                                  item_query.format(mms_id=str(row['MMS_ID']),\n",
    "                                                    holding_id=str(row['Holdings_ID']),\n",
    "                                                    item_pid=str(row['Item_ID']),\n",
    "                                                    apikey=apikey)]))\n",
    "        rdict = xmltodict.parse(r.text)\n",
    "        if r.status_code == 429:  # Too many requests--daily limit\n",
    "            print()\n",
    "            print('Reached API request limit for today. Stopping execution.')\n",
    "            print()            \n",
    "            ## Drop this record & everything after from \"filled\"\n",
    "            filled = filled.iloc[:c-1]\n",
    "            break\n",
    "        if r.status_code != 200:\n",
    "            e = xmltodict.parse(r._content)\n",
    "            # Log the error\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                  ' Error FETCHING item ', row['Item_ID'], ': (', r.status_code, ') ',\n",
    "                  e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "                  sep='',\n",
    "                  file=err_log)\n",
    "            # Remove this item from the \"filled\" df\n",
    "            filled = filled.drop([index])\n",
    "            continue\n",
    "        if (c % (records/100) < 1):\n",
    "            print(int(100*c/records), '% complete', sep='')#, end='\\r')\n",
    "            sleep(5)\n",
    "            \n",
    "        # Merge derived values into the retrieved data (rdict)\n",
    "        rdict['item']['item_data']['enumeration_a'] = str(row['Enum_A'])\n",
    "        rdict['item']['item_data']['enumeration_b'] = str(row['Enum_B'])\n",
    "        rdict['item']['item_data']['chronology_i'] = str(row['Chron_I'])\n",
    "        rdict['item']['item_data']['chronology_j'] = str(row['Chron_J'])\n",
    "        # Set an internal note, if there's an empty one available\n",
    "        if ('Enum/Chron derived from Description' not in rdict['item']['item_data'].values()):\n",
    "            if (not rdict['item']['item_data']['internal_note_1']):\n",
    "                rdict['item']['item_data']['internal_note_1'] = 'Enum/Chron derived from Description'\n",
    "            elif (not rdict['item']['item_data']['internal_note_2']):\n",
    "                rdict['item']['item_data']['internal_note_2'] = 'Enum/Chron derived from Description'\n",
    "            elif (not rdict['item']['item_data']['internal_note_3']):\n",
    "                rdict['item']['item_data']['internal_note_3'] = 'Enum/Chron derived from Description'\n",
    "            else: # Nbd, just log it\n",
    "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                      ' No internal note available for item MMS ID ',\n",
    "                      str(row['MMS_ID']), sep=\"\", file=err_log)\n",
    " \n",
    "        # Push the altered record back into Alma\n",
    "        pxml = xmltodict.unparse(rdict)\n",
    "        p = requests.put(''.join([baseurl,\n",
    "                                  item_query.format(mms_id=row['MMS_ID'],\n",
    "                                                    holding_id=row['Holdings_ID'],\n",
    "                                                    item_pid=row['Item_ID'],\n",
    "                                                    apikey=apikey)]),\n",
    "                         data=pxml.encode('utf-8'), headers={'Content-Type': 'application/xml'})\n",
    "        if r.status_code == 429:  # Too many requests--daily limit\n",
    "            print()\n",
    "            print('Reached API request limit for today. Stopping execution.')\n",
    "            print()            \n",
    "            ## Drop this record & everything after from \"filled\"\n",
    "            filled = filled.iloc[:c-1]\n",
    "            break\n",
    "        if p.status_code != 200:\n",
    "            e = xmltodict.parse(p._content)\n",
    "            # Log the error\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), ' Error UPDATING item ', row['Item_ID'], ': (', p.status_code, ') ',\n",
    "                e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "                sep='', file=err_log)\n",
    "            # Remove this item from the \"filled\" df\n",
    "            filled = filled.drop([index])\n",
    "            continue\n",
    "        print(c, ' / '.join([row['MMS_ID'], row['Holdings_ID'], row['Item_ID']]),\n",
    "              row['Description'],\n",
    "              ' | '.join(x or '' for x in [row['Enum_A'], row['Enum_B'], row['Chron_I'], row['Chron_J']]),\n",
    "              sep=\"\\t\")\n",
    "\n",
    "        # Log it to the CSV\n",
    "        #    Btw, the 'to_frame().T' transposes it, so it all goes in as a single comma-separated row\n",
    "        row.to_frame().T.to_csv(filled_csv, mode='a', index=False, header=needs_header)\n",
    "        needs_header = False # Henceforth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c1766",
   "metadata": {},
   "source": [
    "#### Purge filled rows from the original CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e16ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purge filled records from the original df\n",
    "df = df.loc[~df['Item_ID'].isin(filled['Item_ID'])]\n",
    "\n",
    "# Re-create the original CSV from that df\n",
    "df.to_csv(exported_csv, index=False) # By default, will overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e271555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f22e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3016a14",
   "metadata": {},
   "source": [
    "# View df & filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab226630",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "display(filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517d2ba",
   "metadata": {},
   "source": [
    "# <span style=\"color:#cc0000\">Undo</span> changes to some records!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6805ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "undo_csv=\"Undo.csv\"\n",
    "df = pd.read_csv(undo_csv, converters={'Item_ID': str, 'Holdings_ID': str, 'MMS_ID': str, 'Item ID': str, 'Holdings ID': str, 'MMS ID': str, 'Enum_A': str, 'Enum_B': str, 'Chron_I': str, 'Chron_J': str})\n",
    "# Remove spaces from column names\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "# Rename certain columns\n",
    "df = df.rename(columns={'Permanent_Location': 'Location', 'Item_Policy': 'Policy', 'Material_Type': 'Material'})\n",
    "records = len(df)\n",
    "c = 0\n",
    "\n",
    "for index, row in df.fillna('').iterrows():\n",
    "    c += 1\n",
    "    \n",
    "    # Get the current record\n",
    "    print(c, ' / '.join((row['MMS_ID'], row['Holdings_ID'], row['Item_ID'])), str(row['Description']), sep=\"\\t\")\n",
    "    r = requests.get(''.join([baseurl,\n",
    "                              item_query.format(mms_id=str(row['MMS_ID']),\n",
    "                                                holding_id=str(row['Holdings_ID']),\n",
    "                                                item_pid=str(row['Item_ID']),\n",
    "                                                apikey=apikey)]))\n",
    "    rdict = xmltodict.parse(r.text)\n",
    "    if r.status_code != 200:\n",
    "        e = xmltodict.parse(r._content)\n",
    "        # Output the error\n",
    "        print('Error FETCHING item ', row['Item_ID'], ': (', r.status_code, ') ',\n",
    "            e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "            sep='')\n",
    "        continue\n",
    "    if (c % (records/100) < 1):\n",
    "        print(int(100*c/records), '% complete', sep='')#, end='\\r')\n",
    "        sleep(5)\n",
    "\n",
    "    # Merge derived values into the retrieved data (rdict)\n",
    "    rdict['item']['item_data']['enumeration_a'] = \\\n",
    "        rdict['item']['item_data']['enumeration_b'] = \\\n",
    "        rdict['item']['item_data']['chronology_i'] = \\\n",
    "        rdict['item']['item_data']['chronology_j'] = None\n",
    "    # Set an internal note, if there's an empty one available\n",
    "    if (rdict['item']['item_data']['internal_note_1'] == 'Enum/Chron derived from Description'):\n",
    "        rdict['item']['item_data']['internal_note_1'] = None\n",
    "    if (rdict['item']['item_data']['internal_note_2'] == 'Enum/Chron derived from Description'):\n",
    "        rdict['item']['item_data']['internal_note_2'] = None\n",
    "    if (rdict['item']['item_data']['internal_note_3'] == 'Enum/Chron derived from Description'):\n",
    "        rdict['item']['item_data']['internal_note_3'] = None\n",
    "\n",
    "    # Push the altered record back into Alma\n",
    "    pxml = xmltodict.unparse(rdict)\n",
    "    p = requests.put(''.join([baseurl,\n",
    "                              item_query.format(mms_id=row['MMS_ID'],\n",
    "                                                holding_id=row['Holdings_ID'],\n",
    "                                                item_pid=row['Item_ID'],\n",
    "                                                apikey=apikey)]),\n",
    "                     data=pxml.encode('utf-8'), headers={'Content-Type': 'application/xml'})\n",
    "    if p.status_code != 200:\n",
    "        e = xmltodict.parse(p._content)\n",
    "        # Log the error\n",
    "        print('Error UPDATING item ', row['Item_ID'], ': (', p.status_code, ') ',\n",
    "            e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "            sep='')\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb63aa",
   "metadata": {},
   "source": [
    "# Testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4e97c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 11), match='Spring 1885'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = 'Spring 1885'\n",
    "mmmRE = r'(Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|June?|July?|Aug(?:ust)?|Sept?(?:ember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?|Spr(?:ing)?|Sum(?:mer)?|Fall?|Aut(?:umn)?|Win(?:ter)?)'\n",
    "yyyyRE = r'(?:1[89]|20)\\d\\d(?:[\\-\\/](?:1[89]|20)?\\d\\d)?'\n",
    "exp = re.compile('^' + mmmRE + ' *' + yyyyRE + '$')\n",
    "\n",
    "exp.match(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b21074b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fne = r'^v\\. ?(\\d+)[ \\/]no\\. ?(\\d+) (' + mmmRE + r' \\d{1,2}),? '+'(' + yyyyRE + ')$', ['Enum_A', 'Enum_B', 'Chron_J', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5fef9b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Material</th>\n",
       "      <th>Policy</th>\n",
       "      <th>Title</th>\n",
       "      <th>MMS_ID</th>\n",
       "      <th>Holdings_ID</th>\n",
       "      <th>Item_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Enum_A</th>\n",
       "      <th>Enum_B</th>\n",
       "      <th>Chron_I</th>\n",
       "      <th>Chron_J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1L Cataloging</td>\n",
       "      <td>Other</td>\n",
       "      <td>Serial</td>\n",
       "      <td>Cataloging service bulletin index</td>\n",
       "      <td>991001247819706388</td>\n",
       "      <td>2267069970006388</td>\n",
       "      <td>2367069950006388</td>\n",
       "      <td>no.1-128 1978-2010</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1L Cataloging</td>\n",
       "      <td>Other</td>\n",
       "      <td>Serial</td>\n",
       "      <td>The Music OCLC Users Group presents the best o...</td>\n",
       "      <td>991000134449706388</td>\n",
       "      <td>2276843580006388</td>\n",
       "      <td>2376843570006388</td>\n",
       "      <td>2000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1L Magazine Stand</td>\n",
       "      <td>Issue</td>\n",
       "      <td>Non Circulating</td>\n",
       "      <td>The antelope newspaper</td>\n",
       "      <td>991001196859706388</td>\n",
       "      <td>22130215730006388</td>\n",
       "      <td>23130215550006388</td>\n",
       "      <td>v.123 no.16 Mar 23 2022</td>\n",
       "      <td>123</td>\n",
       "      <td>16</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Mar 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1L Magazine Stand</td>\n",
       "      <td>Issue</td>\n",
       "      <td>Non Circulating</td>\n",
       "      <td>The antelope newspaper</td>\n",
       "      <td>991001196859706388</td>\n",
       "      <td>22130215730006388</td>\n",
       "      <td>23130215560006388</td>\n",
       "      <td>v.123 no.14 Mar 2 2022</td>\n",
       "      <td>123</td>\n",
       "      <td>14</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Mar 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1L Magazine Stand</td>\n",
       "      <td>Issue</td>\n",
       "      <td>Non Circulating</td>\n",
       "      <td>The antelope newspaper</td>\n",
       "      <td>991001196859706388</td>\n",
       "      <td>22130215730006388</td>\n",
       "      <td>23130215570006388</td>\n",
       "      <td>v.123 no.15 Mar 9 2022</td>\n",
       "      <td>123</td>\n",
       "      <td>15</td>\n",
       "      <td>Mar</td>\n",
       "      <td>Mar 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104235</th>\n",
       "      <td>Special Collection</td>\n",
       "      <td>Other</td>\n",
       "      <td>Serial</td>\n",
       "      <td>Work paper</td>\n",
       "      <td>991000171229706388</td>\n",
       "      <td>2266649730006388</td>\n",
       "      <td>2366649680006388</td>\n",
       "      <td>no.20 Spr 1976</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104236</th>\n",
       "      <td>Special Collection</td>\n",
       "      <td>Other</td>\n",
       "      <td>Serial</td>\n",
       "      <td>Work paper</td>\n",
       "      <td>991000171229706388</td>\n",
       "      <td>2266649730006388</td>\n",
       "      <td>2366649690006388</td>\n",
       "      <td>no.19 Dec 1975</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104237</th>\n",
       "      <td>Special Collection</td>\n",
       "      <td>Other</td>\n",
       "      <td>Serial</td>\n",
       "      <td>Work paper</td>\n",
       "      <td>991000171229706388</td>\n",
       "      <td>2266649730006388</td>\n",
       "      <td>2366649700006388</td>\n",
       "      <td>no.18 Sep 1975</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104238</th>\n",
       "      <td>Special Collection</td>\n",
       "      <td>Other</td>\n",
       "      <td>Serial</td>\n",
       "      <td>Work paper</td>\n",
       "      <td>991000171229706388</td>\n",
       "      <td>2266649730006388</td>\n",
       "      <td>2366649710006388</td>\n",
       "      <td>no.13 Dec 1973</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104239</th>\n",
       "      <td>Special Collection</td>\n",
       "      <td>Other</td>\n",
       "      <td>Serial</td>\n",
       "      <td>Work paper</td>\n",
       "      <td>991000171229706388</td>\n",
       "      <td>2266649730006388</td>\n",
       "      <td>2366649720006388</td>\n",
       "      <td>no.9 Oct 1972</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104240 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Location Material           Policy  \\\n",
       "0            1L Cataloging    Other           Serial   \n",
       "1            1L Cataloging    Other           Serial   \n",
       "2        1L Magazine Stand    Issue  Non Circulating   \n",
       "3        1L Magazine Stand    Issue  Non Circulating   \n",
       "4        1L Magazine Stand    Issue  Non Circulating   \n",
       "...                    ...      ...              ...   \n",
       "104235  Special Collection    Other           Serial   \n",
       "104236  Special Collection    Other           Serial   \n",
       "104237  Special Collection    Other           Serial   \n",
       "104238  Special Collection    Other           Serial   \n",
       "104239  Special Collection    Other           Serial   \n",
       "\n",
       "                                                    Title              MMS_ID  \\\n",
       "0                       Cataloging service bulletin index  991001247819706388   \n",
       "1       The Music OCLC Users Group presents the best o...  991000134449706388   \n",
       "2                                  The antelope newspaper  991001196859706388   \n",
       "3                                  The antelope newspaper  991001196859706388   \n",
       "4                                  The antelope newspaper  991001196859706388   \n",
       "...                                                   ...                 ...   \n",
       "104235                                         Work paper  991000171229706388   \n",
       "104236                                         Work paper  991000171229706388   \n",
       "104237                                         Work paper  991000171229706388   \n",
       "104238                                         Work paper  991000171229706388   \n",
       "104239                                         Work paper  991000171229706388   \n",
       "\n",
       "              Holdings_ID            Item_ID              Description Enum_A  \\\n",
       "0        2267069970006388   2367069950006388       no.1-128 1978-2010   None   \n",
       "1        2276843580006388   2376843570006388                     2000   None   \n",
       "2       22130215730006388  23130215550006388  v.123 no.16 Mar 23 2022    123   \n",
       "3       22130215730006388  23130215560006388   v.123 no.14 Mar 2 2022    123   \n",
       "4       22130215730006388  23130215570006388   v.123 no.15 Mar 9 2022    123   \n",
       "...                   ...                ...                      ...    ...   \n",
       "104235   2266649730006388   2366649680006388           no.20 Spr 1976   None   \n",
       "104236   2266649730006388   2366649690006388           no.19 Dec 1975   None   \n",
       "104237   2266649730006388   2366649700006388           no.18 Sep 1975   None   \n",
       "104238   2266649730006388   2366649710006388           no.13 Dec 1973   None   \n",
       "104239   2266649730006388   2366649720006388            no.9 Oct 1972   None   \n",
       "\n",
       "       Enum_B Chron_I Chron_J  \n",
       "0        None    None    None  \n",
       "1        None    None    None  \n",
       "2          16     Mar  Mar 23  \n",
       "3          14     Mar   Mar 2  \n",
       "4          15     Mar   Mar 9  \n",
       "...       ...     ...     ...  \n",
       "104235   None    None    None  \n",
       "104236   None    None    None  \n",
       "104237   None    None    None  \n",
       "104238   None    None    None  \n",
       "104239   None    None    None  \n",
       "\n",
       "[104240 rows x 12 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fde678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
