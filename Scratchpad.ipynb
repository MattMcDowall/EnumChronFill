{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186fdbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os.path import exists as file_exists\n",
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "import re\n",
    "import requests\n",
    "from time import sleep\n",
    "import xmltodict\n",
    "import Credentials      # Get API keys, etc.\n",
    "\n",
    "apikey = Credentials.prod_api\n",
    "baseurl = 'https://api-na.hosted.exlibrisgroup.com'\n",
    "item_query = '/almaws/v1/bibs/{mms_id}/holdings/{holding_id}/items/{item_pid}?apikey={apikey}'\n",
    "\n",
    "exported_csv = \"FullItemList.csv\"\n",
    "filled_csv = \"FilledEnumChron.csv\"\n",
    "err_log_txt = \"log.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee282a0",
   "metadata": {},
   "source": [
    "### Run this cell if you want to use the Limited-list CSV\n",
    "exported_csv = \"LimitedList.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60e89d",
   "metadata": {},
   "source": [
    "#### Create original df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b0706ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on how the file was exported, column names may or may have either spaces or underscores\n",
    "df = pd.read_csv(exported_csv, converters={'Item_ID': str, 'Holdings_ID': str, 'MMS_ID': str, 'Item ID': str, 'Holdings ID': str, 'MMS ID': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5918ffd4",
   "metadata": {},
   "source": [
    "#### Clean up, tweak & format df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7adaf483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces from column names\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "# Rename certain columns\n",
    "df = df.rename(columns={'Permanent_Location': 'Location', 'Item_Policy': 'Policy', 'Material_Type': 'Material'})\n",
    "# Strip leading/trailing space from Description\n",
    "df.Description = df.Description.str.strip()\n",
    "# Collapse multiple spaces within the Description\n",
    "df.Description.replace(' +', ' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c337513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns for the Enum/Chron fields\n",
    "EC_fields = ['Enum_A', 'Enum_B', 'Chron_I', 'Chron_J']\n",
    "df[EC_fields] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bfde9",
   "metadata": {},
   "source": [
    "#### The function for getting info from Description to Enum/Chron fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "983e780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_extract(regex, these_fields):\n",
    "    exp = re.compile(regex)\n",
    "    for i, f in enumerate(these_fields):\n",
    "        df[f] = df['Description'].str.extract(exp, expand=True)[i].fillna(df[f])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0daf1",
   "metadata": {},
   "source": [
    "#### Call it repeatedly for each regex that you come up with:\n",
    "**[Test your Regex here](https://regex101.com/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8576ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just volume & nothing else\n",
    "fill_and_extract(r'^v\\. ?(\\d+)$', ['Enum_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aee6e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just issue & nothing else\n",
    "fill_and_extract(r'^no\\. ?(\\d+)$', ['Enum_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9703742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just year or range of years (post-18th-century) & nothing else\n",
    "fill_and_extract(r'^((?:1[89]|20)\\d{2}(?:-(?:1[89]|20)?\\d{2})?)$', ['Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dff7e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume + year (or range of years)\n",
    "fill_and_extract(r'^v\\. ?(\\d+) ((?:1[89]|20)\\d{2}(?:[\\-\\/](?:1[89]|20)?\\d{2})?)$', ['Enum_A', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7ef8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue + year (or range of years)\n",
    "fill_and_extract(r'^no\\. ?(\\d+) ((?:1[89]|20)\\d{2}(?:[\\-\\/](?:1[89]|20)?\\d{2})?)$', ['Enum_B', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af8e22",
   "metadata": {},
   "source": [
    "#### Then once all those replacements are done, pull filled-in records out to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "184ebb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to hold JUST records that get filled\n",
    "filled = pd.DataFrame()\n",
    "# Populate the new dataframe with any records that now have at least one Enum/Chron field filled\n",
    "filled = df.dropna(subset=EC_fields, thresh=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a955610",
   "metadata": {},
   "source": [
    "#### Then apply the changes via the API and log filled items to the Filled CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca0ea802",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = len(filled)\n",
    "c = 0\n",
    "needs_header=not file_exists(filled_csv) # Apparently we're creating the file, so it needs a header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da865fb5",
   "metadata": {},
   "source": [
    "### Run this bit to see what got \"filled\" before hitting the API\n",
    "\n",
    "for index, row in filled.fillna('').iterrows():\n",
    "    c += 1\n",
    "    print(c, ' / '.join([row['MMS_ID'], row['Holdings_ID'], row['Item_ID']]),\n",
    "          str(row['Description']),\n",
    "          ' | '.join(x or '' for x in [row['Enum_A'], row['Enum_B'], row['Chron_I'], row['Chron_J']]),\n",
    "          sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96dd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t991003653479706388 / 2274276260006388 / 2374276220006388\tv.13 2013\t13 |  | 2013 | \n",
      "2\t991003653479706388 / 2274276260006388 / 2374276230006388\tv.12 2013\t12 |  | 2013 | \n",
      "3\t991003653479706388 / 2274276260006388 / 2374276240006388\tv.11 2012\t11 |  | 2012 | \n",
      "4\t991003653479706388 / 2274276260006388 / 2374276250006388\tv.10 2012\t10 |  | 2012 | \n",
      "5\t991002600689706388 / 2268835710006388 / 2368835530006388\tv.19\t19 |  |  | \n",
      "6\t991002600689706388 / 2268835710006388 / 2368835540006388\tv.18\t18 |  |  | \n",
      "7\t991002600689706388 / 2268835710006388 / 2368835550006388\tv.17\t17 |  |  | \n",
      "8\t991002600689706388 / 2268835710006388 / 2368835560006388\tv.16\t16 |  |  | \n",
      "9\t991002600689706388 / 2268835710006388 / 2368835570006388\tv.15\t15 |  |  | \n",
      "10\t991002600689706388 / 2268835710006388 / 2368835580006388\tv.14\t14 |  |  | \n",
      "1% complete\n",
      "11\t991002600689706388 / 2268835710006388 / 2368835590006388\tv.13\t13 |  |  | \n",
      "12\t991002600689706388 / 2268835710006388 / 2368835600006388\tv.12\t12 |  |  | \n",
      "13\t991002600689706388 / 2268835710006388 / 2368835610006388\tv.11\t11 |  |  | \n",
      "14\t991002600689706388 / 2268835710006388 / 2368835620006388\tv.10\t10 |  |  | \n",
      "15\t991000917249706388 / 2263830780006388 / 2363830760006388\tv.21\t21 |  |  | \n",
      "16\t991003551199706388 / 2270531540006388 / 2370531520006388\tv.41\t41 |  |  | \n",
      "17\t991003551199706388 / 2270531540006388 / 2370531530006388\tv.40\t40 |  |  | \n",
      "18\t991001614419706388 / 2266584650006388 / 2366584580006388\tv.15\t15 |  |  | \n",
      "19\t991001614419706388 / 2266584650006388 / 2366584590006388\tv.14\t14 |  |  | \n",
      "20\t991001614419706388 / 2266584650006388 / 2366584600006388\tv.13\t13 |  |  | \n",
      "21\t991001614419706388 / 2266584650006388 / 2366584610006388\tv.16\t16 |  |  | \n",
      "2% complete\n",
      "22\t991001614419706388 / 2266584650006388 / 2366584620006388\tv.12\t12 |  |  | \n",
      "23\t991001614419706388 / 2266584650006388 / 2366584630006388\tv.10\t10 |  |  | \n",
      "24\t991002753439706388 / 2268726930006388 / 2368726890006388\tv.38\t38 |  |  | \n",
      "25\t991002753439706388 / 2268726930006388 / 2368726900006388\tv.40\t40 |  |  | \n",
      "26\t991002753439706388 / 2268726930006388 / 2368726910006388\tv.37\t37 |  |  | \n",
      "27\t991002753439706388 / 2268726930006388 / 2368726920006388\tv.39\t39 |  |  | \n",
      "28\t991003946689706388 / 2260639080006388 / 2360638630006388\tv.17\t17 |  |  | \n",
      "29\t991003946689706388 / 2260639080006388 / 2360638680006388\tv.21\t21 |  |  | \n",
      "30\t991003946689706388 / 2260639080006388 / 2360638690006388\tv.27\t27 |  |  | \n",
      "31\t991003946689706388 / 2260639080006388 / 2360638720006388\tv.26\t26 |  |  | \n",
      "32\t991003946689706388 / 2260639080006388 / 2360638730006388\tv.25\t25 |  |  | \n",
      "3% complete\n",
      "33\t991003946689706388 / 2260639080006388 / 2360638740006388\tv.28\t28 |  |  | \n",
      "34\t991003946689706388 / 2260639080006388 / 2360638750006388\tv.24\t24 |  |  | \n",
      "35\t991003946689706388 / 2260639080006388 / 2360638760006388\tv.23\t23 |  |  | \n"
     ]
    }
   ],
   "source": [
    "with open(err_log_txt, 'a') as err_log:\n",
    "    for index, row in filled.fillna('').iterrows():\n",
    "        c += 1\n",
    "        r = requests.get(''.join([baseurl,\n",
    "                                  item_query.format(mms_id=str(row['MMS_ID']),\n",
    "                                                    holding_id=str(row['Holdings_ID']),\n",
    "                                                    item_pid=str(row['Item_ID']),\n",
    "                                                    apikey=apikey)]))\n",
    "        rdict = xmltodict.parse(r.text)\n",
    "        if r.status_code == 429:  # Too many requests--daily limit\n",
    "            print()\n",
    "            print('Reached API request limit for today. Stopping execution.')\n",
    "            print()            \n",
    "            ## Drop this record & everything after from \"filled\"\n",
    "            filled = filled.iloc[:c-1]\n",
    "            break\n",
    "        if r.status_code != 200:\n",
    "            e = xmltodict.parse(r._content)\n",
    "            # Log the error\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                  ' Error FETCHING item ', row['Item_ID'], ': (', r.status_code, ') ',\n",
    "                  e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "                  sep='',\n",
    "                  file=err_log)\n",
    "            # Remove this item from the \"filled\" df\n",
    "            filled = filled.drop([index])\n",
    "            continue\n",
    "        if (c % (records/100) < 1):\n",
    "            print(int(100*c/records), '% complete', sep='')#, end='\\r')\n",
    "            sleep(5)\n",
    "            \n",
    "        # Merge derived values into the retrieved data (rdict)\n",
    "        rdict['item']['item_data']['enumeration_a'] = str(row['Enum_A'])\n",
    "        rdict['item']['item_data']['enumeration_b'] = str(row['Enum_B'])\n",
    "        rdict['item']['item_data']['chronology_i'] = str(row['Chron_I'])\n",
    "        rdict['item']['item_data']['chronology_j'] = str(row['Chron_J'])\n",
    "        # Set an internal note, if there's an empty one available\n",
    "        if ('Enum/Chron derived from Description' not in rdict['item']['item_data'].values()):\n",
    "            if (not rdict['item']['item_data']['internal_note_1']):\n",
    "                rdict['item']['item_data']['internal_note_1'] = 'Enum/Chron derived from Description'\n",
    "            elif (not rdict['item']['item_data']['internal_note_2']):\n",
    "                rdict['item']['item_data']['internal_note_2'] = 'Enum/Chron derived from Description'\n",
    "            elif (not rdict['item']['item_data']['internal_note_3']):\n",
    "                rdict['item']['item_data']['internal_note_3'] = 'Enum/Chron derived from Description'\n",
    "            else: # Nbd, just log it\n",
    "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), ' No internal note available for item MMS ID ',\n",
    "                    str(row['MMS_ID']), sep=\"\", file=err_log)\n",
    " \n",
    "        # Push the altered record back into Alma\n",
    "        pxml = xmltodict.unparse(rdict)\n",
    "        p = requests.put(''.join([baseurl,\n",
    "                                  item_query.format(mms_id=row['MMS_ID'],\n",
    "                                                    holding_id=row['Holdings_ID'],\n",
    "                                                    item_pid=row['Item_ID'],\n",
    "                                                    apikey=apikey)]),\n",
    "                         data=pxml.encode('utf-8'), headers={'Content-Type': 'application/xml'})\n",
    "        if r.status_code == 429:  # Too many requests--daily limit\n",
    "            print()\n",
    "            print('Reached API request limit for today. Stopping execution.')\n",
    "            print()            \n",
    "            ## Drop this record & everything after from \"filled\"\n",
    "            filled = filled.iloc[:c-1]\n",
    "            break\n",
    "        if p.status_code != 200:\n",
    "            e = xmltodict.parse(p._content)\n",
    "            # Log the error\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), ' Error UPDATING item ', row['Item_ID'], ': (', p.status_code, ') ',\n",
    "                e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "                sep='', file=err_log)\n",
    "            # Remove this item from the \"filled\" df\n",
    "            filled = filled.drop([index])\n",
    "            continue\n",
    "        print(c, ' / '.join([row['MMS_ID'], row['Holdings_ID'], row['Item_ID']]),\n",
    "              row['Description'],\n",
    "              ' | '.join(x or '' for x in [row['Enum_A'], row['Enum_B'], row['Chron_I'], row['Chron_J']]),\n",
    "              sep=\"\\t\")\n",
    "\n",
    "        # Log it to the CSV\n",
    "        #    Btw, the 'to_frame().T' transposes it, so it all goes in as a single comma-separated row\n",
    "        row.to_frame().T.to_csv(filled_csv, mode='a', index=False, header=needs_header)\n",
    "        needs_header = False # Henceforth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c1766",
   "metadata": {},
   "source": [
    "#### Purge filled rows from the original CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e16ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purge filled records from the original df\n",
    "df = df.loc[~df['Item_ID'].isin(filled['Item_ID'])]\n",
    "\n",
    "# Re-create the original CSV from that df\n",
    "df.to_csv(exported_csv, index=False) # By default, will overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e271555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f22e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3016a14",
   "metadata": {},
   "source": [
    "# View df & filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab226630",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)\n",
    "display(filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517d2ba",
   "metadata": {},
   "source": [
    "# <span style=\"color:#cc0000\">Undo</span> changes to some records!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6805ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "undo_csv=\"Undo.csv\"\n",
    "df = pd.read_csv(undo_csv, converters={'Item_ID': str, 'Holdings_ID': str, 'MMS_ID': str, 'Item ID': str, 'Holdings ID': str, 'MMS ID': str, 'Enum_A': str, 'Enum_B': str, 'Chron_I': str, 'Chron_J': str})\n",
    "# Remove spaces from column names\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "# Rename certain columns\n",
    "df = df.rename(columns={'Permanent_Location': 'Location', 'Item_Policy': 'Policy', 'Material_Type': 'Material'})\n",
    "records = len(df)\n",
    "c = 0\n",
    "\n",
    "for index, row in df.fillna('').iterrows():\n",
    "    c += 1\n",
    "    \n",
    "    # Get the current record\n",
    "    print(c, ' / '.join((row['MMS_ID'], row['Holdings_ID'], row['Item_ID'])), str(row['Description']), sep=\"\\t\")\n",
    "    r = requests.get(''.join([baseurl,\n",
    "                              item_query.format(mms_id=str(row['MMS_ID']),\n",
    "                                                holding_id=str(row['Holdings_ID']),\n",
    "                                                item_pid=str(row['Item_ID']),\n",
    "                                                apikey=apikey)]))\n",
    "    rdict = xmltodict.parse(r.text)\n",
    "    if r.status_code != 200:\n",
    "        e = xmltodict.parse(r._content)\n",
    "        # Output the error\n",
    "        print('Error FETCHING item ', row['Item_ID'], ': (', r.status_code, ') ',\n",
    "            e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "            sep='')\n",
    "        continue\n",
    "    if (c % (records/100) < 1):\n",
    "        print(int(100*c/records), '% complete', sep='')#, end='\\r')\n",
    "        sleep(5)\n",
    "\n",
    "    # Merge derived values into the retrieved data (rdict)\n",
    "    rdict['item']['item_data']['enumeration_a'] = \\\n",
    "        rdict['item']['item_data']['enumeration_b'] = \\\n",
    "        rdict['item']['item_data']['chronology_i'] = \\\n",
    "        rdict['item']['item_data']['chronology_j'] = None\n",
    "    # Set an internal note, if there's an empty one available\n",
    "    if (rdict['item']['item_data']['internal_note_1'] == 'Enum/Chron derived from Description'):\n",
    "        rdict['item']['item_data']['internal_note_1'] = None\n",
    "    if (rdict['item']['item_data']['internal_note_2'] == 'Enum/Chron derived from Description'):\n",
    "        rdict['item']['item_data']['internal_note_2'] = None\n",
    "    if (rdict['item']['item_data']['internal_note_3'] == 'Enum/Chron derived from Description'):\n",
    "        rdict['item']['item_data']['internal_note_3'] = None\n",
    "\n",
    "    # Push the altered record back into Alma\n",
    "    pxml = xmltodict.unparse(rdict)\n",
    "    p = requests.put(''.join([baseurl,\n",
    "                              item_query.format(mms_id=row['MMS_ID'],\n",
    "                                                holding_id=row['Holdings_ID'],\n",
    "                                                item_pid=row['Item_ID'],\n",
    "                                                apikey=apikey)]),\n",
    "                     data=pxml.encode('utf-8'), headers={'Content-Type': 'application/xml'})\n",
    "    if p.status_code != 200:\n",
    "        e = xmltodict.parse(p._content)\n",
    "        # Log the error\n",
    "        print('Error UPDATING item ', row['Item_ID'], ': (', p.status_code, ') ',\n",
    "            e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "            sep='')\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eb63aa",
   "metadata": {},
   "source": [
    "# Testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c4e97c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = 'Spring 1885'\n",
    "mmmRE = '(Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|June?|July?|Aug(?:ust)?|Sept?(?:ember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?|Spr(?:ing)?|Sum(?:mer)?|Fall?|Aut(?:umn)?|Win(?:ter)?)'\n",
    "yyyyRE = '(1[89]|20)\\d\\d'\n",
    "exp = re.compile('^' + mmmRE + ' *' + yyyyRE + '$')\n",
    "\n",
    "exp.match(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b21074b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "undo_csv=\"Undo.csv\"\n",
    "df = pd.read_csv(undo_csv, converters={'Item_ID': str, 'Holdings_ID': str, 'MMS_ID': str, 'Item ID': str, 'Holdings ID': str, 'MMS ID': str, 'Enum_A': str, 'Enum_B': str, 'Chron_I': str, 'Chron_J': str})\n",
    "# Remove spaces from column names\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "# Rename certain columns\n",
    "df = df.rename(columns={'Permanent_Location': 'Location', 'Item_Policy': 'Policy', 'Material_Type': 'Material'})\n",
    "records = len(df)\n",
    "c = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0906951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Description'].str.match('^v. ?\\d\\d+')==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "703dab92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Material</th>\n",
       "      <th>Policy</th>\n",
       "      <th>Title</th>\n",
       "      <th>MMS_ID</th>\n",
       "      <th>Holdings_ID</th>\n",
       "      <th>Item_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Enum_A</th>\n",
       "      <th>Enum_B</th>\n",
       "      <th>Chron_I</th>\n",
       "      <th>Chron_J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>2L Ref Gov Doc Index Table</td>\n",
       "      <td>Book</td>\n",
       "      <td>Non Circulating</td>\n",
       "      <td>United States treaty index, 1776- /</td>\n",
       "      <td>991003653479706388</td>\n",
       "      <td>2274276260006388</td>\n",
       "      <td>2374276220006388</td>\n",
       "      <td>v.13 2013</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>2013</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5964</th>\n",
       "      <td>2L Ref Gov Doc Index Table</td>\n",
       "      <td>Book</td>\n",
       "      <td>Non Circulating</td>\n",
       "      <td>United States treaty index, 1776- /</td>\n",
       "      <td>991003653479706388</td>\n",
       "      <td>2274276260006388</td>\n",
       "      <td>2374276230006388</td>\n",
       "      <td>v.12 2013</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>2013</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5965</th>\n",
       "      <td>2L Ref Gov Doc Index Table</td>\n",
       "      <td>Book</td>\n",
       "      <td>Non Circulating</td>\n",
       "      <td>United States treaty index, 1776- /</td>\n",
       "      <td>991003653479706388</td>\n",
       "      <td>2274276260006388</td>\n",
       "      <td>2374276240006388</td>\n",
       "      <td>v.11 2012</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2012</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5966</th>\n",
       "      <td>2L Ref Gov Doc Index Table</td>\n",
       "      <td>Book</td>\n",
       "      <td>Non Circulating</td>\n",
       "      <td>United States treaty index, 1776- /</td>\n",
       "      <td>991003653479706388</td>\n",
       "      <td>2274276260006388</td>\n",
       "      <td>2374276250006388</td>\n",
       "      <td>v.10 2012</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2012</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>2L Stacks</td>\n",
       "      <td>Book</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>Catalogue of scientific papers</td>\n",
       "      <td>991002600689706388</td>\n",
       "      <td>2268835710006388</td>\n",
       "      <td>2368835530006388</td>\n",
       "      <td>v.19</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15692</th>\n",
       "      <td>2L Stacks</td>\n",
       "      <td>Book</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>The Medallion edition of the works of Joseph C...</td>\n",
       "      <td>991000246179706388</td>\n",
       "      <td>2266601050006388</td>\n",
       "      <td>2366600830006388</td>\n",
       "      <td>v.21</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15693</th>\n",
       "      <td>2L Stacks</td>\n",
       "      <td>Book</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>The Medallion edition of the works of Joseph C...</td>\n",
       "      <td>991000246179706388</td>\n",
       "      <td>2266601050006388</td>\n",
       "      <td>2366600840006388</td>\n",
       "      <td>v.22</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15694</th>\n",
       "      <td>2L Stacks</td>\n",
       "      <td>Book</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>The Medallion edition of the works of Joseph C...</td>\n",
       "      <td>991000246179706388</td>\n",
       "      <td>2266601050006388</td>\n",
       "      <td>2366600850006388</td>\n",
       "      <td>v.20</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15695</th>\n",
       "      <td>2L Stacks</td>\n",
       "      <td>Book</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>The Medallion edition of the works of Joseph C...</td>\n",
       "      <td>991000246179706388</td>\n",
       "      <td>2266601050006388</td>\n",
       "      <td>2366600860006388</td>\n",
       "      <td>v.19</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15696</th>\n",
       "      <td>2L Stacks</td>\n",
       "      <td>Book</td>\n",
       "      <td>Monograph</td>\n",
       "      <td>The Medallion edition of the works of Joseph C...</td>\n",
       "      <td>991000246179706388</td>\n",
       "      <td>2266601050006388</td>\n",
       "      <td>2366600870006388</td>\n",
       "      <td>v.18</td>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1098 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Location Material           Policy  \\\n",
       "5963   2L Ref Gov Doc Index Table     Book  Non Circulating   \n",
       "5964   2L Ref Gov Doc Index Table     Book  Non Circulating   \n",
       "5965   2L Ref Gov Doc Index Table     Book  Non Circulating   \n",
       "5966   2L Ref Gov Doc Index Table     Book  Non Circulating   \n",
       "6083                    2L Stacks     Book        Monograph   \n",
       "...                           ...      ...              ...   \n",
       "15692                   2L Stacks     Book        Monograph   \n",
       "15693                   2L Stacks     Book        Monograph   \n",
       "15694                   2L Stacks     Book        Monograph   \n",
       "15695                   2L Stacks     Book        Monograph   \n",
       "15696                   2L Stacks     Book        Monograph   \n",
       "\n",
       "                                                   Title              MMS_ID  \\\n",
       "5963                 United States treaty index, 1776- /  991003653479706388   \n",
       "5964                 United States treaty index, 1776- /  991003653479706388   \n",
       "5965                 United States treaty index, 1776- /  991003653479706388   \n",
       "5966                 United States treaty index, 1776- /  991003653479706388   \n",
       "6083                      Catalogue of scientific papers  991002600689706388   \n",
       "...                                                  ...                 ...   \n",
       "15692  The Medallion edition of the works of Joseph C...  991000246179706388   \n",
       "15693  The Medallion edition of the works of Joseph C...  991000246179706388   \n",
       "15694  The Medallion edition of the works of Joseph C...  991000246179706388   \n",
       "15695  The Medallion edition of the works of Joseph C...  991000246179706388   \n",
       "15696  The Medallion edition of the works of Joseph C...  991000246179706388   \n",
       "\n",
       "            Holdings_ID           Item_ID Description Enum_A Enum_B Chron_I  \\\n",
       "5963   2274276260006388  2374276220006388   v.13 2013      3           2013   \n",
       "5964   2274276260006388  2374276230006388   v.12 2013      2           2013   \n",
       "5965   2274276260006388  2374276240006388   v.11 2012      1           2012   \n",
       "5966   2274276260006388  2374276250006388   v.10 2012      0           2012   \n",
       "6083   2268835710006388  2368835530006388        v.19      9                  \n",
       "...                 ...               ...         ...    ...    ...     ...   \n",
       "15692  2266601050006388  2366600830006388        v.21      1                  \n",
       "15693  2266601050006388  2366600840006388        v.22      2                  \n",
       "15694  2266601050006388  2366600850006388        v.20      0                  \n",
       "15695  2266601050006388  2366600860006388        v.19      9                  \n",
       "15696  2266601050006388  2366600870006388        v.18      8                  \n",
       "\n",
       "      Chron_J  \n",
       "5963           \n",
       "5964           \n",
       "5965           \n",
       "5966           \n",
       "6083           \n",
       "...       ...  \n",
       "15692          \n",
       "15693          \n",
       "15694          \n",
       "15695          \n",
       "15696          \n",
       "\n",
       "[1098 rows x 12 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "425f8d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t991001602639706388 / 2276187460006388 / 2376187390006388\t1900\t |  | 1900 | \n"
     ]
    }
   ],
   "source": [
    "print(c, ' / '.join([row['MMS_ID'], row['Holdings_ID'], row['Item_ID']]),\n",
    "              row['Description'],\n",
    "              ' | '.join(x or '' for x in [row['Enum_A'], row['Enum_B'], row['Chron_I'], row['Chron_J']]),\n",
    "              sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
