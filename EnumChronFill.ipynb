{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defaf138",
   "metadata": {},
   "source": [
    "#### Import modules, initialize variables, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24f90dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:28:25.545388Z",
     "start_time": "2023-05-10T15:28:25.536068Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from os.path import exists as file_exists\n",
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "import re\n",
    "import requests\n",
    "from time import sleep\n",
    "import xmltodict\n",
    "import Credentials      # Get API keys, etc.\n",
    "\n",
    "apikey = Credentials.prod_api\n",
    "baseurl = 'https://api-na.hosted.exlibrisgroup.com'\n",
    "item_query = '/almaws/v1/bibs/{mms_id}/holdings/{holding_id}/items/{item_pid}?apikey={apikey}'\n",
    "\n",
    "exported_csv = \"FullItemList.csv\"\n",
    "filled_csv = \"FilledEnumChron.csv\"\n",
    "err_log_txt = \"log.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e8439",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Read CSV into Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4d3f841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:33:23.939140Z",
     "start_time": "2023-05-10T15:33:23.923011Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Depending on how the file was exported, column names may or may have either spaces or underscores\n",
    "df = pd.read_csv(exported_csv, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb5d6ae",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Clean up, tweak & format df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be370074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:33:24.780143Z",
     "start_time": "2023-05-10T15:33:24.767104Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove spaces from column names\n",
    "df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "# Rename certain columns\n",
    "df = df.rename(columns={'Permanent_Location':'Location',\n",
    "                        'Item_Policy': 'Policy',\n",
    "                        'Material_Type': 'Material'})\n",
    "# Strip leading/trailing space from Description\n",
    "df.Description = df.Description.str.strip()\n",
    "# Collapse multiple spaces within the Description\n",
    "df.Description.replace(' +', ' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "412f91d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:33:25.174471Z",
     "start_time": "2023-05-10T15:33:25.166273Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Exclude special cases—GovDocs of certain material types, with weird numbering\n",
    "df = df[~((df['Material'].isin(['Issue','Microform','Other'])) & (df['Location'].isin(['gdmo','gdrf','gdrfi','govdo'])))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67abea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T14:11:46.883865Z",
     "start_time": "2023-05-10T14:11:46.879872Z"
    },
    "hidden": true
   },
   "source": [
    "#### Add empty columns for the Enum/Chron fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6233479c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:33:26.664858Z",
     "start_time": "2023-05-10T15:33:26.659817Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add empty columns for the Enum/Chron fields\n",
    "EC_fields = ['Enum_A', 'Enum_B', 'Chron_I', 'Chron_J']\n",
    "df[EC_fields] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7eb1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:33:27.992157Z",
     "start_time": "2023-05-10T15:33:27.977159Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a151c",
   "metadata": {},
   "source": [
    "### The function for getting info from Description to Enum/Chron fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "266db3ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:28:28.324997Z",
     "start_time": "2023-05-10T15:28:28.318001Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_and_fill(regex, these_fields):\n",
    "    exp = re.compile(regex, re.IGNORECASE)\n",
    "    for i, f in enumerate(these_fields):\n",
    "        df[f] = df['Description'].str.extract(exp, expand=True)[i].fillna(df[f])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa936d89",
   "metadata": {},
   "source": [
    "**[Test your Regex here](https://regex101.com/)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360ea05",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Examples of usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15332283",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:28:29.616104Z",
     "start_time": "2023-05-10T15:28:29.599108Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Records with just a volume number:\n",
    "extract_and_fill(r'^v\\.(\\d+)$', ['Enum_A'])\n",
    "\n",
    "# Records with just a volume number and issue number:\n",
    "extract_and_fill(r'^v\\.(\\d+) no\\.(\\d+)$', ['Enum_A', 'Enum_B'])\n",
    "\n",
    "# Records with just a volume number and year:\n",
    "extract_and_fill(r'^v\\.(\\d+) (\\d{4})$', ['Enum_A', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ac3d01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:30:06.523988Z",
     "start_time": "2023-05-10T15:30:06.504305Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a8f2b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Set some common expressions that can be used in a modular way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd2abfa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:28:31.817975Z",
     "start_time": "2023-05-10T15:28:31.812940Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Single volume/book - CAPTURE\n",
    "vvvRE = r'(?:v|bk)\\. ?(\\d+[a-z]?)'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee84829",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a4d54b",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Volume(s)/book(s) - CAPTURE\n",
    "vvv_vvRE = vvvRE[:-1] + r'(?:[\\&\\-]\\d+)?)'\n",
    "# Index/Supp/etc\n",
    "iiiiRE = r'(?:abstracts?|addendum|brief|Directory|exec(?:utive)? summ(?:ary)?|guide|handbook|(?:author |cum |master |subj )?Index(?:es)?|revisions?|spec(?:ial(?:edition|issue|rep|report)?)?|Suppl?\\.?(?: \\d+)? ?)|title sheet|updates?'\n",
    "# Month/season\n",
    "mmmRE = r'(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|June?|July?|Aug(?:ust)?|Sept?(?:ember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?|Spr(?:ing)?|Sum(?:mer)?|Fall?|Aut(?:umn)?|Win(?:ter)?)'\n",
    "# Month + date(s)\n",
    "mmm_ddRE = mmmRE + r'(?: \\d{1,2}(?:[\\-\\/]\\d{1,2})?)?'\n",
    "# 4-digit year/range of years (post–18th-century)\n",
    "yyyyRE = r'(?:1[89]|20)\\d{2}'\n",
    "# 4-digit year leading to a range\n",
    "#   E.g., 1976-89\n",
    "yyyy_yyRE = r'(?:1[89]|20)\\d{2}(?:-\\d{2}|-\\d{4})?'\n",
    "# 4-digit year leading to a range, possibly using a SLASH\n",
    "#   E.g., 1976/89\n",
    "#   Beware false positives\n",
    "#   Remember to replace the slash with a hyphen in the Chron_I\n",
    "yyyy_SyyRE = r'(?:1[89]|20)\\d{2}(?:[\\-\\/]\\d{2}|[\\-\\/]\\d{4})?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f7f00",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Call it repeatedly for each regex that you come up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b27015cc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Just volume(s) & nothing else\n",
    "extract_and_fill(r'^' + vvv_vvRE + '$',\n",
    "                 ['Enum_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00742ede",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Volume + issue\n",
    "extract_and_fill(r'^' + vvvRE + '[ \\/]no\\. ?(\\d+)$',\n",
    "                 ['Enum_A', 'Enum_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66963d44",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vol + issue + year\n",
    "extract_and_fill(r'^' + vvvRE + r'[ \\/]no\\. ?(\\d+) (' + yyyyRE + r')$',\n",
    "    ['Enum_A', 'Enum_B', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "209c3bed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Vol + issue + date + year\n",
    "extract_and_fill(r'^' + vvvRE + '[ \\/]no\\. ?(\\d+) (' + mmm_ddRE + r'),? (' + yyyyRE + ')$',\n",
    "                 ['Enum_A', 'Enum_B', 'Chron_J', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b96a5d4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Volume(s) + \"Index\"\n",
    "extract_and_fill(r'^' + vvv_vvRE + ' (' + iiiiRE + r')$',\n",
    "                 ['Enum_A', 'Enum_C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06a65902",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Volume + year(s)\n",
    "extract_and_fill(r'^' + vvv_vvRE + ' +\\(?(' + yyyy_yyRE + r')\\)?$',\n",
    "                 ['Enum_A', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5836c972",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Volume + part(s)\n",
    "extract_and_fill(r'^' + vvvRE + r' pt\\. ?(\\d+[a-z]?(?:[\\&\\-]\\d+)?)$',\n",
    "    ['Enum_A', 'Enum_C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b9605af",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Just issue & nothing else\n",
    "extract_and_fill(r'^no\\. ?(\\d+)$',\n",
    "                 ['Enum_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "df308f4c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Issue + date + year\n",
    "extract_and_fill(r'^no\\. ?(\\d+) (' + mmm_ddRE + ') (' + yyyy_yyRE + r')$',\n",
    "                 ['Enum_B', 'Chron_J', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ac745e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Issue + year(s)\n",
    "extract_and_fill(r'^no\\. ?(\\d+) (' + yyyy_yyRE + r')$',\n",
    "                 ['Enum_B', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8191cd04",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Just part(s) & nothing else\n",
    "extract_and_fill(r'^pt\\. ?(\\d+[a-z]?(?:[\\&\\-]\\d+)?)$',\n",
    "                 ['Enum_C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0ef8c1f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Just year/range of years\n",
    "extract_and_fill(r'^(' + yyyy_yyRE + r')$',\n",
    "                 ['Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ef9a03d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Year(s) + volume(s)\n",
    "extract_and_fill(r'^(' + yyyy_yyRE + r') ' + vvv_vvRE + '$',\n",
    "                 ['Chron_I', 'Enum_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "96a6d20a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Year(s) + part(s)\n",
    "extract_and_fill(r'^(' + yyyy_yyRE + r') pt\\. ?(\\d+(?:[\\-\\/]\\d+)?)$',\n",
    "                 ['Chron_I', 'Enum_C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "264bd9c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Year(s) + \"Index\"\n",
    "extract_and_fill(r'^(' + yyyy_yyRE + r') (' + iiiiRE + r')$',\n",
    "                 ['Chron_I', 'Enum_C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45a848d9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Year + month/season/date\n",
    "extract_and_fill(r'^(' + yyyyRE + r') (' + mmm_ddRE + r')$',\n",
    "                 ['Chron_I', 'Chron_J'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "730cdc86",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Range of dates within one calendar year\n",
    "extract_and_fill(r'^(' + mmm_ddRE + r'[\\-\\/]' + mmm_ddRE + '), (' + yyyyRE + ')$',\n",
    "                 ['Chron_J', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "7f1704ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Range of dates and range of years (only capture years)\n",
    "extract_and_fill(r'^' + mmm_ddRE + r'[\\-\\/]' + mmm_ddRE + ', (' + yyyyRE + r'[\\-\\/]\\d\\d(?:\\d\\d)?)$',\n",
    "    ['Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d20160e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Date + year\n",
    "extract_and_fill(r'^(' + mmm_ddRE + '),? (' + yyyyRE + ')$',\n",
    "                 ['Chron_J', 'Chron_I'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "eb29d194",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SPECIAL CASES: Range of dates spanning across years\n",
    "#   Only capture the year range, not the dates\n",
    "# ex. \"April 1976-February 1980\" ⇒ 1976-1980\n",
    "exp = re.compile(r'^' + mmm_ddRE + ',? (' + yyyyRE + ') ?- ?' + mmm_ddRE + ',? (' + yyyyRE + ')$')\n",
    "for row, years in df['Description'].str.extract(exp, expand=True).dropna().apply('-'.join, axis=1).items():\n",
    "    df.at[row, 'Chron_I'] = years\n",
    "# ex. \"Nov 11-May 16, 1977-1978\"\n",
    "exp = re.compile(r'^' + mmm_ddRE + ' ?- ?' + mmm_ddRE + ' (' + yyyy_SyyRE + ')$')\n",
    "for row, years in df['Description'].str.extract(exp, expand=True).dropna().apply('-'.join, axis=1).items():\n",
    "    df.at[row, 'Chron_I'] = years.replace('/', '-')\n",
    "# ex. \"Nov 11-May 16, 1977-1978\"\n",
    "exp = re.compile(r'^' + mmm_ddRE + ' ?- ?' + mmm_ddRE + ' (' + yyyy_SyyRE + ')$')\n",
    "for row, years in df['Description'].str.extract(exp, expand=True).dropna().apply('-'.join, axis=1).items():\n",
    "    df.at[row, 'Chron_I'] = years.replace('/', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "1108bd30",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SPECIAL CASES: Range of volumes spanning across years\n",
    "# ex. \"v.16-20 1976-1980\"\n",
    "exp = re.compile(r'^' + vvv_vvRE + ' (' + yyyy_yyRE + ')$')\n",
    "for i, field in enumerate(['Enum_A', 'Chron_I']):\n",
    "    for row, x in df['Description'].str.extract(exp, expand=True).dropna()[i].items():\n",
    "        df.at[row, field] = x\n",
    "# ex. \"v.76 Jan 16, 1986-v.80 Dec 1989\"\n",
    "#   Ignore dates, capture vols & years\n",
    "exp = re.compile(r'^' + vvvRE + ' ' + mmm_ddRE + r',? (' + yyyyRE + ') ?- ?' + vvvRE + ' ' + mmm_ddRE + r',? (' + yyyyRE + ')$')\n",
    "for item, field in enumerate(['Enum_A', 'Chron_I']):\n",
    "    for row, x in df['Description'].str.extract(exp, expand=True).dropna()[[item, item + 2]].apply('-'.join, axis=1).items():\n",
    "        df.at[row, field] = x\n",
    "# ex. \"v.43-45 Jun 21-Jan 30, 1928/30\"\n",
    "#   Ignore dates, capture vols & years\n",
    "exp = re.compile(r'^' + vvv_vvRE + ' ' + mmm_ddRE + ' ?- ?' + mmm_ddRE + ',? (' + yyyy_SyyRE + ')$')\n",
    "for i, field in enumerate(['Enum_A', 'Chron_I']):\n",
    "    for row, x in df['Description'].str.extract(exp, expand=True).dropna()[i].items():\n",
    "        df.at[row, field] = x.replace('/', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c301d9b",
   "metadata": {},
   "source": [
    "### Once all those replacements are done, pull filled-in records out to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dc2f9f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T14:40:36.221730Z",
     "start_time": "2023-05-10T14:40:36.207726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe to hold JUST records that get filled\n",
    "filled = pd.DataFrame()\n",
    "# Populate the new dataframe with any records that now have at least one Enum/Chron field filled\n",
    "filled = df.dropna(subset=EC_fields, thresh=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df015b59",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### View df & filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62fd6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T15:29:55.167142Z",
     "start_time": "2023-05-10T15:29:55.148602Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaea5b4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "___________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa3a965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T14:47:18.628628Z",
     "start_time": "2023-05-10T14:47:18.609025Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a116a57",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Apply the changes via the API and log filled items to the Filled CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ba61d1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Run this bit to see what got \"filled\" before hitting the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c9b0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-08T21:28:07.002615Z",
     "start_time": "2023-05-08T21:28:06.965686Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for index, row in filled.fillna('').iterrows():\n",
    "    c += 1\n",
    "    print(c, ' / '.join([row['MMS_ID'], row['Holdings_ID'], row['Item_ID']]),\n",
    "          str(row['Description']),\n",
    "          ' | '.join(x or '' for x in [row['Enum_A'], row['Enum_B'], row['Enum_C'], row['Chron_I'], row['Chron_J']]),\n",
    "          sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804089ad",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### This actually applies the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a4fae2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "records = len(filled)\n",
    "# If the \"filled\" file doesn't exist, note that we'll need a header\n",
    "needs_header=not file_exists(filled_csv)\n",
    "\n",
    "with open(err_log_txt, 'a') as err_log:\n",
    "    for index, row in filled.fillna('').iterrows():\n",
    "        c += 1\n",
    "        r = requests.get(''.join([baseurl,\n",
    "                                  item_query.format(mms_id=str(row['MMS_ID']),\n",
    "                                                    holding_id=str(row['Holdings_ID']),\n",
    "                                                    item_pid=str(row['Item_ID']),\n",
    "                                                    apikey=apikey)]))\n",
    "        rdict = xmltodict.parse(r.text)\n",
    "        if r.status_code == 429:  # Too many requests--daily limit\n",
    "            print()\n",
    "            print('Reached API request limit for today. Stopping execution.')\n",
    "            print()            \n",
    "            ## Drop this record & everything after from \"filled\"\n",
    "            filled = filled.iloc[:c-1]\n",
    "            break\n",
    "        if r.status_code != 200:\n",
    "            e = xmltodict.parse(r._content)\n",
    "            # Log the error\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                  ' Error FETCHING item ', row['Item_ID'], ': (', r.status_code, ') ',\n",
    "                  e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "                  sep='',\n",
    "                  file=err_log)\n",
    "            # Remove this item from the \"filled\" df\n",
    "            filled = filled.drop([index])\n",
    "            continue\n",
    "        if (c % (records/100) < 1):\n",
    "            print(int(100*c/records), '% complete', sep='')#, end='\\r')\n",
    "            sleep(5)\n",
    "            \n",
    "        # Merge derived values into the retrieved data (rdict)\n",
    "        \n",
    "        rdict['item']['item_data']['description'] = str(row['Description'])\n",
    "        \n",
    "        rdict['item']['item_data']['enumeration_a'] = str(row['Enum_A'])\n",
    "        rdict['item']['item_data']['enumeration_b'] = str(row['Enum_B'])\n",
    "        rdict['item']['item_data']['enumeration_c'] = str(row['Enum_C'])\n",
    "        rdict['item']['item_data']['chronology_i'] = str(row['Chron_I'])\n",
    "        rdict['item']['item_data']['chronology_j'] = str(row['Chron_J'])\n",
    "        # Set an internal note, if there's an empty one available\n",
    "        if ('Enum/Chron derived from Description' not in rdict['item']['item_data'].values()):\n",
    "            if (not rdict['item']['item_data']['internal_note_1']):\n",
    "                rdict['item']['item_data']['internal_note_1'] = 'Enum/Chron derived from Description'\n",
    "            elif (not rdict['item']['item_data']['internal_note_2']):\n",
    "                rdict['item']['item_data']['internal_note_2'] = 'Enum/Chron derived from Description'\n",
    "            elif (not rdict['item']['item_data']['internal_note_3']):\n",
    "                rdict['item']['item_data']['internal_note_3'] = 'Enum/Chron derived from Description'\n",
    "            else: # Nbd, just log it\n",
    "                print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                      ' No internal note available for item MMS ID ',\n",
    "                      str(row['MMS_ID']), sep=\"\", file=err_log)\n",
    " \n",
    "        # Push the altered record back into Alma\n",
    "        pxml = xmltodict.unparse(rdict)\n",
    "        p = requests.put(''.join([baseurl,\n",
    "                                  item_query.format(mms_id=row['MMS_ID'],\n",
    "                                                    holding_id=row['Holdings_ID'],\n",
    "                                                    item_pid=row['Item_ID'],\n",
    "                                                    apikey=apikey)]),\n",
    "                         data=pxml.encode('utf-8'), headers={'Content-Type': 'application/xml'})\n",
    "        if r.status_code == 429:  # Too many requests--daily limit\n",
    "            print()\n",
    "            print('Reached API request limit for today. Stopping execution.')\n",
    "            print()            \n",
    "            ## Drop this record & everything after from \"filled\"\n",
    "            filled = filled.iloc[:c-1]\n",
    "            break\n",
    "        if p.status_code != 200:\n",
    "            e = xmltodict.parse(p._content)\n",
    "            # Log the error\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), ' Error UPDATING item ', row['Item_ID'], ': (', p.status_code, ') ',\n",
    "                e['web_service_result']['errorList']['error']['errorMessage'],\n",
    "                sep='', file=err_log)\n",
    "            # Remove this item from the \"filled\" df\n",
    "            filled = filled.drop([index])\n",
    "            continue\n",
    "        print(c, ' / '.join([row['MMS_ID'], row['Holdings_ID'], row['Item_ID']]),\n",
    "              row['Description'],\n",
    "              ' | '.join(x or '' for x in [row['Enum_A'], row['Enum_B'], row['Chron_I'], row['Chron_J']]),\n",
    "              sep=\"\\t\")\n",
    "\n",
    "        # Log it to the CSV\n",
    "        #    Btw, the 'to_frame().T' transposes it, so it all goes in as a single comma-separated row\n",
    "        row.to_frame().T.to_csv(filled_csv, mode='a', index=False, header=needs_header)\n",
    "        needs_header = False # Henceforth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0e6ed",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Purge filled rows from the original CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73877450",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T14:42:33.274977Z",
     "start_time": "2023-05-10T14:42:33.238721Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Purge filled records from the original df\n",
    "df = df.loc[~df['Item_ID'].isin(filled['Item_ID'])]\n",
    "\n",
    "# Re-create the original CSV from that df\n",
    "df.to_csv(exported_csv, index=False) # By default, will overwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf8c14",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Testing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1e852bd9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### SPECIAL CASE: 3-digit Description, which is a year with first digit removed\n",
    "\n",
    "exp = re.compile(r'^(9\\d{2}(?:\\-19\\d{2}|\\-20\\d{2})?)$')\n",
    "df['Chron_I'] = df['Description'] = '1' + df['Description'].str.extract(exp, expand=True).dropna()\n",
    "\n",
    "exp = re.compile(r'^' + vvv_vvRE + ' ' + mmm_ddRE + ' ?- ?' + mmm_ddRE + ',? (' + yyyyRE + '[\\-\\/]\\d\\d(?:\\d\\d)?)$')\n",
    "for i, field in enumerate(['Enum_A', 'Chron_I']):\n",
    "    for row, x in df['Description'].str.extract(exp, expand=True).dropna()[i].items():\n",
    "#         df.at[row, field] = x.replace('/', '-')\n",
    "        print(row, field, x.replace('/', '-'))\n",
    "\n",
    "df['Chron_I'] = df['Description'] = '1' + df['Description'].str.extract(exp, expand=True).fillna(df['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da66af0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
